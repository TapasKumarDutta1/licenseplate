{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONwczkarX2iR0ObnZYbMx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/hardhat/blob/main/yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTPZ4vF8GMQN"
      },
      "source": [
        "def convert_annot(size , box):\n",
        "    x1 = int(box[0])\n",
        "    y1 = int(box[1])\n",
        "    x2 = int(box[2])\n",
        "    y2 = int(box[3])\n",
        "\n",
        "    dw = np.float32(1. / int(size[0]))\n",
        "    dh = np.float32(1. / int(size[1]))\n",
        "\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    x = x1 + (w / 2)\n",
        "    y = y1 + (h / 2)\n",
        "\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return [x, y, w, h]\n",
        "def save_txt_file(img_jpg_file_name, size, img_box):\n",
        "    save_file_name = '/content/Dataset/labels/' +  img_jpg_file_name + '.txt'\n",
        "    #file_path = open(save_file_name, \"a+\")\n",
        "    with open(save_file_name ,'a+') as file_path:\n",
        "        for box in img_box:\n",
        "\n",
        "            cls_num = classes.index(box[0])\n",
        "\n",
        "            new_box = convert_annot(size, box[1:])\n",
        "\n",
        "            file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n",
        "\n",
        "        file_path.flush()\n",
        "        file_path.close()\n",
        "def get_xml_data(file_path, img_xml_file):\n",
        "    img_path = file_path + '/' + img_xml_file + '.xml'\n",
        "    #print(img_path)\n",
        "\n",
        "    dom = parse(img_path)\n",
        "    root = dom.documentElement\n",
        "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
        "    img_size = root.getElementsByTagName(\"size\")[0]\n",
        "    objects = root.getElementsByTagName(\"object\")\n",
        "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
        "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
        "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
        "   \n",
        "    img_box = []\n",
        "    for box in objects:\n",
        "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
        "        if cls_name=='helmet':\n",
        "            x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
        "            y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
        "            x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
        "            y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
        "\n",
        "            img_jpg_file_name = img_xml_file + '.jpg'\n",
        "            img_box.append([cls_name, x1, y1, x2, y2])\n",
        "\n",
        "    # test_dataset_box_feature(img_jpg_file_name, img_box)\n",
        "    save_txt_file(img_xml_file, [img_w, img_h], img_box)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajcxOJo7GNm2"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "from pathlib import Path\n",
        "from xml.dom.minidom import parse\n",
        "from shutil import copyfile\n",
        "import os\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZahgzSbmGNkO"
      },
      "source": [
        "%%writefile train.py\n",
        "\"\"\"Train a YOLOv5 model on a custom dataset\n",
        "\n",
        "Usage:\n",
        "    $ python path/to/train.py --data coco128.yaml --weights yolov5s.pt --img 640\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "from threading import Thread\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import torch.distributed as dist\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.utils.data\n",
        "import yaml\n",
        "from torch.cuda import amp\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "FILE = Path(__file__).absolute()\n",
        "sys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path\n",
        "\n",
        "import val  # for end-of-epoch mAP\n",
        "from models.experimental import attempt_load\n",
        "from models.yolo import Model\n",
        "from utils.autoanchor import check_anchors\n",
        "from utils.datasets import create_dataloader\n",
        "from utils.general import labels_to_class_weights, increment_path, labels_to_image_weights, init_seeds, \\\n",
        "    strip_optimizer, get_latest_run, check_dataset, check_file, check_git_status, check_img_size, \\\n",
        "    check_requirements, print_mutation, set_logging, one_cycle, colorstr\n",
        "from utils.google_utils import attempt_download\n",
        "from utils.loss import ComputeLoss\n",
        "from utils.plots import plot_images, plot_labels, plot_results, plot_evolution\n",
        "from utils.torch_utils import ModelEMA, select_device, intersect_dicts, torch_distributed_zero_first, de_parallel\n",
        "from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume\n",
        "from utils.metrics import fitness\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\n",
        "RANK = int(os.getenv('RANK', -1))\n",
        "WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n",
        "\n",
        "\n",
        "def train(hyp,  # path/to/hyp.yaml or hyp dictionary\n",
        "          opt,\n",
        "          device,\n",
        "          ):\n",
        "    save_dir, epochs, batch_size, weights, single_cls, evolve, data, cfg, resume, noval, nosave, workers, = \\\n",
        "        opt.save_dir, opt.epochs, opt.batch_size, opt.weights, opt.single_cls, opt.evolve, opt.data, opt.cfg, \\\n",
        "        opt.resume, opt.noval, opt.nosave, opt.workers\n",
        "\n",
        "    # Directories\n",
        "    save_dir = Path(save_dir)\n",
        "    wdir = save_dir / 'weights'\n",
        "    wdir.mkdir(parents=True, exist_ok=True)  # make dir\n",
        "    last = wdir / 'last.pt'\n",
        "    best = wdir / 'best.pt'\n",
        "    results_file = save_dir / 'results.txt'\n",
        "\n",
        "    # Hyperparameters\n",
        "    if isinstance(hyp, str):\n",
        "        with open(hyp) as f:\n",
        "            hyp = yaml.safe_load(f)  # load hyps dict\n",
        "    logger.info(colorstr('hyperparameters: ') + ', '.join(f'{k}={v}' for k, v in hyp.items()))\n",
        "\n",
        "    # Save run settings\n",
        "    with open(save_dir / 'hyp.yaml', 'w') as f:\n",
        "        yaml.safe_dump(hyp, f, sort_keys=False)\n",
        "    with open(save_dir / 'opt.yaml', 'w') as f:\n",
        "        yaml.safe_dump(vars(opt), f, sort_keys=False)\n",
        "\n",
        "    # Configure\n",
        "    plots = not evolve  # create plots\n",
        "    cuda = device.type != 'cpu'\n",
        "    init_seeds(1 + RANK)\n",
        "    with open(data) as f:\n",
        "        data_dict = yaml.safe_load(f)  # data dict\n",
        "\n",
        "    # Loggers\n",
        "    loggers = {'wandb': None, 'tb': None}  # loggers dict\n",
        "    if RANK in [-1, 0]:\n",
        "        # TensorBoard\n",
        "        if not evolve:\n",
        "            prefix = colorstr('tensorboard: ')\n",
        "            logger.info(f\"{prefix}Start with 'tensorboard --logdir {opt.project}', view at http://localhost:6006/\")\n",
        "            loggers['tb'] = SummaryWriter(str(save_dir))\n",
        "\n",
        "        # W&B\n",
        "        opt.hyp = hyp  # add hyperparameters\n",
        "        run_id = torch.load(weights).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
        "        run_id = run_id if opt.resume else None  # start fresh run if transfer learning\n",
        "        wandb_logger = WandbLogger(opt, save_dir.stem, run_id, data_dict)\n",
        "        loggers['wandb'] = wandb_logger.wandb\n",
        "        if loggers['wandb']:\n",
        "            data_dict = wandb_logger.data_dict\n",
        "            weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp  # may update weights, epochs if resuming\n",
        "\n",
        "    nc = 1 if single_cls else int(data_dict['nc'])  # number of classes\n",
        "    names = ['item'] if single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names\n",
        "    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, data)  # check\n",
        "    is_coco = data.endswith('coco.yaml') and nc == 80  # COCO dataset\n",
        "\n",
        "    # Model\n",
        "    pretrained = weights.endswith('.pt')\n",
        "    if pretrained:\n",
        "        with torch_distributed_zero_first(RANK):\n",
        "            weights = attempt_download(weights)  # download if not found locally\n",
        "        ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
        "        model = Model(cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
        "        exclude = ['anchor'] if (cfg or hyp.get('anchors')) and not resume else []  # exclude keys\n",
        "        state_dict = ckpt['model'].float().state_dict()  # to FP32\n",
        "        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect\n",
        "        model.load_state_dict(state_dict, strict=False)  # load\n",
        "        logger.info('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), weights))  # report\n",
        "    else:\n",
        "        model = Model(cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create\n",
        "    with torch_distributed_zero_first(RANK):\n",
        "        check_dataset(data_dict)  # check\n",
        "    train_path = data_dict['train']\n",
        "    val_path = data_dict['val']\n",
        "\n",
        "    # Freeze\n",
        "    freeze = []  # parameter names to freeze (full or partial)\n",
        "    for k, v in model.named_parameters():\n",
        "        v.requires_grad = True  # train all layers\n",
        "        if any(x in k for x in freeze):\n",
        "            print('freezing %s' % k)\n",
        "            v.requires_grad = False\n",
        "\n",
        "    # Optimizer\n",
        "    nbs = 64  # nominal batch size\n",
        "    accumulate = max(round(nbs / batch_size), 1)  # accumulate loss before optimizing\n",
        "    hyp['weight_decay'] *= batch_size * accumulate / nbs  # scale weight_decay\n",
        "    logger.info(f\"Scaled weight_decay = {hyp['weight_decay']}\")\n",
        "\n",
        "    pg0, pg1, pg2 = [], [], []  # optimizer parameter groups\n",
        "    for k, v in model.named_modules():\n",
        "        if hasattr(v, 'bias') and isinstance(v.bias, nn.Parameter):\n",
        "            pg2.append(v.bias)  # biases\n",
        "        if isinstance(v, nn.BatchNorm2d):\n",
        "            pg0.append(v.weight)  # no decay\n",
        "        elif hasattr(v, 'weight') and isinstance(v.weight, nn.Parameter):\n",
        "            pg1.append(v.weight)  # apply decay\n",
        "\n",
        "    if opt.adam:\n",
        "        optimizer = optim.Adam(pg0, lr=hyp['lr0'], betas=(hyp['momentum'], 0.999))  # adjust beta1 to momentum\n",
        "    else:\n",
        "        optimizer = optim.SGD(pg0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
        "\n",
        "    optimizer.add_param_group({'params': pg1, 'weight_decay': hyp['weight_decay']})  # add pg1 with weight_decay\n",
        "    optimizer.add_param_group({'params': pg2})  # add pg2 (biases)\n",
        "    logger.info('Optimizer groups: %g .bias, %g conv.weight, %g other' % (len(pg2), len(pg1), len(pg0)))\n",
        "    del pg0, pg1, pg2\n",
        "\n",
        "    # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
        "    # https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR\n",
        "    if opt.linear_lr:\n",
        "        lf = lambda x: (1 - x / (epochs - 1)) * (1.0 - hyp['lrf']) + hyp['lrf']  # linear\n",
        "    else:\n",
        "        lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']\n",
        "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
        "    # plot_lr_scheduler(optimizer, scheduler, epochs)\n",
        "\n",
        "    # EMA\n",
        "    ema = ModelEMA(model) if RANK in [-1, 0] else None\n",
        "\n",
        "    # Resume\n",
        "    start_epoch, best_fitness = 0, 0.0\n",
        "    if pretrained:\n",
        "        # Optimizer\n",
        "        if ckpt['optimizer'] is not None:\n",
        "            optimizer.load_state_dict(ckpt['optimizer'])\n",
        "            best_fitness = ckpt['best_fitness']\n",
        "\n",
        "        # EMA\n",
        "        if ema and ckpt.get('ema'):\n",
        "            ema.ema.load_state_dict(ckpt['ema'].float().state_dict())\n",
        "            ema.updates = ckpt['updates']\n",
        "\n",
        "        # Results\n",
        "        if ckpt.get('training_results') is not None:\n",
        "            results_file.write_text(ckpt['training_results'])  # write results.txt\n",
        "\n",
        "        # Epochs\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "        if resume:\n",
        "            assert start_epoch > 0, '%s training to %g epochs is finished, nothing to resume.' % (weights, epochs)\n",
        "        if epochs < start_epoch:\n",
        "            logger.info('%s has been trained for %g epochs. Fine-tuning for %g additional epochs.' %\n",
        "                        (weights, ckpt['epoch'], epochs))\n",
        "            epochs += ckpt['epoch']  # finetune additional epochs\n",
        "\n",
        "        del ckpt, state_dict\n",
        "\n",
        "    # Image sizes\n",
        "    gs = max(int(model.stride.max()), 32)  # grid size (max stride)\n",
        "    nl = model.model[-1].nl  # number of detection layers (used for scaling hyp['obj'])\n",
        "    imgsz, imgsz_val = [check_img_size(x, gs) for x in opt.img_size]  # verify imgsz are gs-multiples\n",
        "\n",
        "    # DP mode\n",
        "    if cuda and RANK == -1 and torch.cuda.device_count() > 1:\n",
        "        logging.warning('DP not recommended, instead use torch.distributed.run for best DDP Multi-GPU results.\\n'\n",
        "                        'See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.')\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # SyncBatchNorm\n",
        "    if opt.sync_bn and cuda and RANK != -1:\n",
        "        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)\n",
        "        logger.info('Using SyncBatchNorm()')\n",
        "\n",
        "    # Trainloader\n",
        "    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size // WORLD_SIZE, gs, single_cls,\n",
        "                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=RANK,\n",
        "                                            workers=workers,\n",
        "                                            image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))\n",
        "    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class\n",
        "    nb = len(dataloader)  # number of batches\n",
        "    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, data, nc - 1)\n",
        "\n",
        "    # Process 0\n",
        "    if RANK in [-1, 0]:\n",
        "        valloader = create_dataloader(val_path, imgsz_val, batch_size // WORLD_SIZE * 2, gs, single_cls,\n",
        "                                       hyp=hyp, cache=opt.cache_images and not noval, rect=True, rank=-1,\n",
        "                                       workers=workers,\n",
        "                                       pad=0.5, prefix=colorstr('val: '))[0]\n",
        "\n",
        "        if not resume:\n",
        "            labels = np.concatenate(dataset.labels, 0)\n",
        "            c = torch.tensor(labels[:, 0])  # classes\n",
        "            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency\n",
        "            # model._initialize_biases(cf.to(device))\n",
        "            if plots:\n",
        "                plot_labels(labels, names, save_dir, loggers)\n",
        "                if loggers['tb']:\n",
        "                    loggers['tb'].add_histogram('classes', c, 0)  # TensorBoard\n",
        "\n",
        "            # Anchors\n",
        "            if not opt.noautoanchor:\n",
        "                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)\n",
        "            model.half().float()  # pre-reduce anchor precision\n",
        "\n",
        "    # DDP mode\n",
        "    if cuda and RANK != -1:\n",
        "        model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)\n",
        "\n",
        "    # Model parameters\n",
        "    hyp['box'] *= 3. / nl  # scale to layers\n",
        "    hyp['cls'] *= nc / 80. * 3. / nl  # scale to classes and layers\n",
        "    hyp['obj'] *= (imgsz / 640) ** 2 * 3. / nl  # scale to image size and layers\n",
        "    hyp['label_smoothing'] = opt.label_smoothing\n",
        "    model.nc = nc  # attach number of classes to model\n",
        "    model.hyp = hyp  # attach hyperparameters to model\n",
        "    model.gr = 1.0  # iou loss ratio (obj_loss = 1.0 or iou)\n",
        "    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  # attach class weights\n",
        "    model.names = names\n",
        "\n",
        "    # Start training\n",
        "    t0 = time.time()\n",
        "    nw = max(round(hyp['warmup_epochs'] * nb), 1000)  # number of warmup iterations, max(3 epochs, 1k iterations)\n",
        "    # nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training\n",
        "    last_opt_step = -1\n",
        "    maps = np.zeros(nc)  # mAP per class\n",
        "    results = (0, 0, 0, 0, 0, 0, 0)  # P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)\n",
        "    scheduler.last_epoch = start_epoch - 1  # do not move\n",
        "    scaler = amp.GradScaler(enabled=cuda)\n",
        "    compute_loss = ComputeLoss(model)  # init loss class\n",
        "    logger.info(f'Image sizes {imgsz} train, {imgsz_val} val\\n'\n",
        "                f'Using {dataloader.num_workers} dataloader workers\\n'\n",
        "                f'Logging results to {save_dir}\\n'\n",
        "                f'Starting training for {epochs} epochs...')\n",
        "    for epoch in range(start_epoch, epochs):  # epoch ------------------------------------------------------------------\n",
        "        model.train()\n",
        "\n",
        "        # Update image weights (optional)\n",
        "        if opt.image_weights:\n",
        "            # Generate indices\n",
        "            if RANK in [-1, 0]:\n",
        "                cw = model.class_weights.cpu().numpy() * (1 - maps) ** 2 / nc  # class weights\n",
        "                iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  # image weights\n",
        "                dataset.indices = random.choices(range(dataset.n), weights=iw, k=dataset.n)  # rand weighted idx\n",
        "            # Broadcast if DDP\n",
        "            if RANK != -1:\n",
        "                indices = (torch.tensor(dataset.indices) if RANK == 0 else torch.zeros(dataset.n)).int()\n",
        "                dist.broadcast(indices, 0)\n",
        "                if RANK != 0:\n",
        "                    dataset.indices = indices.cpu().numpy()\n",
        "\n",
        "        # Update mosaic border\n",
        "        # b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)\n",
        "        # dataset.mosaic_border = [b - imgsz, -b]  # height, width borders\n",
        "\n",
        "        mloss = torch.zeros(4, device=device)  # mean losses\n",
        "        if RANK != -1:\n",
        "            dataloader.sampler.set_epoch(epoch)\n",
        "        pbar = enumerate(dataloader)\n",
        "        logger.info(('\\n' + '%10s' * 8) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'total', 'labels', 'img_size'))\n",
        "        if RANK in [-1, 0]:\n",
        "            pbar = tqdm(pbar, total=nb)  # progress bar\n",
        "        optimizer.zero_grad()\n",
        "        for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
        "            ni = i + nb * epoch  # number integrated batches (since train start)\n",
        "            imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
        "\n",
        "            # Warmup\n",
        "            if ni <= nw:\n",
        "                xi = [0, nw]  # x interp\n",
        "                # model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
        "                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n",
        "                for j, x in enumerate(optimizer.param_groups):\n",
        "                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
        "                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
        "                    if 'momentum' in x:\n",
        "                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n",
        "\n",
        "            # Multi-scale\n",
        "            if opt.multi_scale:\n",
        "                sz = random.randrange(imgsz * 0.5, imgsz * 1.5 + gs) // gs * gs  # size\n",
        "                sf = sz / max(imgs.shape[2:])  # scale factor\n",
        "                if sf != 1:\n",
        "                    ns = [math.ceil(x * sf / gs) * gs for x in imgs.shape[2:]]  # new shape (stretched to gs-multiple)\n",
        "                    imgs = F.interpolate(imgs, size=ns, mode='bilinear', align_corners=False)\n",
        "\n",
        "            # Forward\n",
        "            with amp.autocast(enabled=cuda):\n",
        "                pred = model(imgs)  # forward\n",
        "                loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size\n",
        "                if RANK != -1:\n",
        "                    loss *= WORLD_SIZE  # gradient averaged between devices in DDP mode\n",
        "                if opt.quad:\n",
        "                    loss *= 4.\n",
        "\n",
        "            # Backward\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Optimize\n",
        "            if ni - last_opt_step >= accumulate:\n",
        "                scaler.step(optimizer)  # optimizer.step\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "                if ema:\n",
        "                    ema.update(model)\n",
        "                last_opt_step = ni\n",
        "\n",
        "            # Print\n",
        "            if RANK in [-1, 0]:\n",
        "                mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
        "                mem = '%.3gG' % (torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0)  # (GB)\n",
        "                s = ('%10s' * 2 + '%10.4g' * 6) % (\n",
        "                    f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0], imgs.shape[-1])\n",
        "                pbar.set_description(s)\n",
        "\n",
        "                # Plot\n",
        "                if plots and ni < 3:\n",
        "                    f = save_dir / f'train_batch{ni}.jpg'  # filename\n",
        "                    Thread(target=plot_images, args=(imgs, targets, paths, f), daemon=True).start()\n",
        "                    if loggers['tb'] and ni == 0:  # TensorBoard\n",
        "                        with warnings.catch_warnings():\n",
        "                            warnings.simplefilter('ignore')  # suppress jit trace warning\n",
        "                            loggers['tb'].add_graph(torch.jit.trace(de_parallel(model), imgs[0:1], strict=False), [])\n",
        "                elif plots and ni == 10 and loggers['wandb']:\n",
        "                    wandb_logger.log({'Mosaics': [loggers['wandb'].Image(str(x), caption=x.name) for x in\n",
        "                                                  save_dir.glob('train*.jpg') if x.exists()]})\n",
        "\n",
        "            # end batch ------------------------------------------------------------------------------------------------\n",
        "\n",
        "        # Scheduler\n",
        "        lr = [x['lr'] for x in optimizer.param_groups]  # for loggers\n",
        "        scheduler.step()\n",
        "\n",
        "        # DDP process 0 or single-GPU\n",
        "        if RANK in [-1, 0]:\n",
        "            # mAP\n",
        "            ema.update_attr(model, include=['yaml', 'nc', 'hyp', 'gr', 'names', 'stride', 'class_weights'])\n",
        "            final_epoch = epoch + 1 == epochs\n",
        "            if not noval or final_epoch:  # Calculate mAP\n",
        "                wandb_logger.current_epoch = epoch + 1\n",
        "                results, maps, _ = val.run(data_dict,\n",
        "                                           batch_size=batch_size // WORLD_SIZE * 2,\n",
        "                                           imgsz=imgsz_val,\n",
        "                                           model=ema.ema,\n",
        "                                           single_cls=single_cls,\n",
        "                                           dataloader=valloader,\n",
        "                                           save_dir=save_dir,\n",
        "                                           save_json=is_coco and final_epoch,\n",
        "                                           verbose=nc < 50 and final_epoch,\n",
        "                                           plots=plots and final_epoch,\n",
        "                                           wandb_logger=wandb_logger,\n",
        "                                           compute_loss=compute_loss)\n",
        "\n",
        "            # Write\n",
        "            with open(results_file, 'a') as f:\n",
        "                f.write(s + '%10.4g' * 7 % results + '\\n')  # append metrics, val_loss\n",
        "\n",
        "            # Log\n",
        "            tags = ['train/box_loss', 'train/obj_loss', 'train/cls_loss',  # train loss\n",
        "                    'metrics/precision', 'metrics/recall', 'metrics/mAP_0.5', 'metrics/mAP_0.5:0.95',\n",
        "                    'val/box_loss', 'val/obj_loss', 'val/cls_loss',  # val loss\n",
        "                    'x/lr0', 'x/lr1', 'x/lr2']  # params\n",
        "            for x, tag in zip(list(mloss[:-1]) + list(results) + lr, tags):\n",
        "                if loggers['tb']:\n",
        "                    loggers['tb'].add_scalar(tag, x, epoch)  # TensorBoard\n",
        "                if loggers['wandb']:\n",
        "                    wandb_logger.log({tag: x})  # W&B\n",
        "\n",
        "            # Update best mAP\n",
        "            fi = fitness(np.array(results).reshape(1, -1))  # weighted combination of [P, R, mAP@.5, mAP@.5-.95]\n",
        "            if fi > best_fitness:\n",
        "                best_fitness = fi\n",
        "            wandb_logger.end_epoch(best_result=best_fitness == fi)\n",
        "\n",
        "            # Save model\n",
        "            if (not nosave) or (final_epoch and not evolve):  # if save\n",
        "                ckpt = {'epoch': epoch,\n",
        "                        'best_fitness': best_fitness,\n",
        "                        'training_results': results_file.read_text(),\n",
        "                        'model': deepcopy(de_parallel(model)).half(),\n",
        "                        'ema': deepcopy(ema.ema).half(),\n",
        "                        'updates': ema.updates,\n",
        "                        'optimizer': optimizer.state_dict(),\n",
        "                        'wandb_id': wandb_logger.wandb_run.id if loggers['wandb'] else None}\n",
        "\n",
        "                # Save last, best and delete\n",
        "                torch.save(ckpt, '/content/gdrive/MyDrive/last.pt')\n",
        "                if best_fitness == fi:\n",
        "                    torch.save(ckpt, '/content/gdrive/MyDrive/best.pt')\n",
        "                if loggers['wandb']:\n",
        "                    if ((epoch + 1) % opt.save_period == 0 and not final_epoch) and opt.save_period != -1:\n",
        "                        wandb_logger.log_model(last.parent, opt, epoch, fi, best_model=best_fitness == fi)\n",
        "                del ckpt\n",
        "\n",
        "        # end epoch ----------------------------------------------------------------------------------------------------\n",
        "    # end training -----------------------------------------------------------------------------------------------------\n",
        "    if RANK in [-1, 0]:\n",
        "        logger.info(f'{epoch - start_epoch + 1} epochs completed in {(time.time() - t0) / 3600:.3f} hours.\\n')\n",
        "        if plots:\n",
        "            plot_results(save_dir=save_dir)  # save as results.png\n",
        "            if loggers['wandb']:\n",
        "                files = ['results.png', 'confusion_matrix.png', *[f'{x}_curve.png' for x in ('F1', 'PR', 'P', 'R')]]\n",
        "                wandb_logger.log({\"Results\": [loggers['wandb'].Image(str(save_dir / f), caption=f) for f in files\n",
        "                                              if (save_dir / f).exists()]})\n",
        "\n",
        "        if not evolve:\n",
        "            if is_coco:  # COCO dataset\n",
        "                for m in [last, best] if best.exists() else [last]:  # speed, mAP tests\n",
        "                    results, _, _ = val.run(data_dict,\n",
        "                                            batch_size=batch_size // WORLD_SIZE * 2,\n",
        "                                            imgsz=imgsz_val,\n",
        "                                            model=attempt_load(m, device).half(),\n",
        "                                            single_cls=single_cls,\n",
        "                                            dataloader=valloader,\n",
        "                                            save_dir=save_dir,\n",
        "                                            save_json=True,\n",
        "                                            plots=False)\n",
        "\n",
        "            # Strip optimizers\n",
        "            for f in last, best:\n",
        "                if f.exists():\n",
        "                    strip_optimizer(f)  # strip optimizers\n",
        "            if loggers['wandb']:  # Log the stripped model\n",
        "                loggers['wandb'].log_artifact(str(best if best.exists() else last), type='model',\n",
        "                                              name='run_' + wandb_logger.wandb_run.id + '_model',\n",
        "                                              aliases=['latest', 'best', 'stripped'])\n",
        "        wandb_logger.finish_run()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    return results\n",
        "\n",
        "\n",
        "def parse_opt(known=False):\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', type=str, default='yolov5s.pt', help='initial weights path')\n",
        "    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n",
        "    parser.add_argument('--data', type=str, default='data/coco128.yaml', help='dataset.yaml path')\n",
        "    parser.add_argument('--hyp', type=str, default='data/hyps/hyp.scratch.yaml', help='hyperparameters path')\n",
        "    parser.add_argument('--epochs', type=int, default=300)\n",
        "    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs')\n",
        "    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='[train, val] image sizes')\n",
        "    parser.add_argument('--rect', action='store_true', help='rectangular training')\n",
        "    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n",
        "    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n",
        "    parser.add_argument('--noval', action='store_true', help='only validate final epoch')\n",
        "    parser.add_argument('--noautoanchor', action='store_true', help='disable autoanchor check')\n",
        "    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')\n",
        "    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n",
        "    parser.add_argument('--cache-images', action='store_true', help='cache images for faster training')\n",
        "    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n",
        "    parser.add_argument('--adam', action='store_true', help='use torch.optim.Adam() optimizer')\n",
        "    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n",
        "    parser.add_argument('--workers', type=int, default=8, help='maximum number of dataloader workers')\n",
        "    parser.add_argument('--project', default='runs/train', help='save to project/name')\n",
        "    parser.add_argument('--entity', default=None, help='W&B entity')\n",
        "    parser.add_argument('--name', default='exp', help='save to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--quad', action='store_true', help='quad dataloader')\n",
        "    parser.add_argument('--linear-lr', action='store_true', help='linear LR')\n",
        "    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')\n",
        "    parser.add_argument('--upload_dataset', action='store_true', help='Upload dataset as W&B artifact table')\n",
        "    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval for W&B')\n",
        "    parser.add_argument('--save_period', type=int, default=-1, help='Log model after every \"save_period\" epoch')\n",
        "    parser.add_argument('--artifact_alias', type=str, default=\"latest\", help='version of dataset artifact to be used')\n",
        "    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')\n",
        "    opt = parser.parse_known_args()[0] if known else parser.parse_args()\n",
        "    return opt\n",
        "\n",
        "\n",
        "def main(opt):\n",
        "    set_logging(RANK)\n",
        "    if RANK in [-1, 0]:\n",
        "        print(colorstr('train: ') + ', '.join(f'{k}={v}' for k, v in vars(opt).items()))\n",
        "        check_git_status()\n",
        "        check_requirements(exclude=['thop'])\n",
        "\n",
        "    # Resume\n",
        "    wandb_run = check_wandb_resume(opt)\n",
        "    if opt.resume and not wandb_run:  # resume an interrupted run\n",
        "        ckpt = opt.resume if isinstance(opt.resume, str) else get_latest_run()  # specified or most recent path\n",
        "        assert os.path.isfile(ckpt), 'ERROR: --resume checkpoint does not exist'\n",
        "        with open(Path(ckpt).parent.parent / 'opt.yaml') as f:\n",
        "            opt = argparse.Namespace(**yaml.safe_load(f))  # replace\n",
        "        opt.cfg, opt.weights, opt.resume = '', ckpt, True  # reinstate\n",
        "        logger.info('Resuming training from %s' % ckpt)\n",
        "    else:\n",
        "        # opt.hyp = opt.hyp or ('hyp.finetune.yaml' if opt.weights else 'hyp.scratch.yaml')\n",
        "        opt.data, opt.cfg, opt.hyp = check_file(opt.data), check_file(opt.cfg), check_file(opt.hyp)  # check files\n",
        "        assert len(opt.cfg) or len(opt.weights), 'either --cfg or --weights must be specified'\n",
        "        opt.img_size.extend([opt.img_size[-1]] * (2 - len(opt.img_size)))  # extend to 2 sizes (train, val)\n",
        "        opt.name = 'evolve' if opt.evolve else opt.name\n",
        "        opt.save_dir = str(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok or opt.evolve))\n",
        "\n",
        "    # DDP mode\n",
        "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
        "    if LOCAL_RANK != -1:\n",
        "        from datetime import timedelta\n",
        "        assert torch.cuda.device_count() > LOCAL_RANK, 'insufficient CUDA devices for DDP command'\n",
        "        torch.cuda.set_device(LOCAL_RANK)\n",
        "        device = torch.device('cuda', LOCAL_RANK)\n",
        "        dist.init_process_group(backend=\"nccl\" if dist.is_nccl_available() else \"gloo\", timeout=timedelta(seconds=60))\n",
        "        assert opt.batch_size % WORLD_SIZE == 0, '--batch-size must be multiple of CUDA device count'\n",
        "        assert not opt.image_weights, '--image-weights argument is not compatible with DDP training'\n",
        "\n",
        "    # Train\n",
        "    if not opt.evolve:\n",
        "        train(opt.hyp, opt, device)\n",
        "        if WORLD_SIZE > 1 and RANK == 0:\n",
        "            _ = [print('Destroying process group... ', end=''), dist.destroy_process_group(), print('Done.')]\n",
        "\n",
        "    # Evolve hyperparameters (optional)\n",
        "    else:\n",
        "        # Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\n",
        "        meta = {'lr0': (1, 1e-5, 1e-1),  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "                'lrf': (1, 0.01, 1.0),  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "                'momentum': (0.3, 0.6, 0.98),  # SGD momentum/Adam beta1\n",
        "                'weight_decay': (1, 0.0, 0.001),  # optimizer weight decay\n",
        "                'warmup_epochs': (1, 0.0, 5.0),  # warmup epochs (fractions ok)\n",
        "                'warmup_momentum': (1, 0.0, 0.95),  # warmup initial momentum\n",
        "                'warmup_bias_lr': (1, 0.0, 0.2),  # warmup initial bias lr\n",
        "                'box': (1, 0.02, 0.2),  # box loss gain\n",
        "                'cls': (1, 0.2, 4.0),  # cls loss gain\n",
        "                'cls_pw': (1, 0.5, 2.0),  # cls BCELoss positive_weight\n",
        "                'obj': (1, 0.2, 4.0),  # obj loss gain (scale with pixels)\n",
        "                'obj_pw': (1, 0.5, 2.0),  # obj BCELoss positive_weight\n",
        "                'iou_t': (0, 0.1, 0.7),  # IoU training threshold\n",
        "                'anchor_t': (1, 2.0, 8.0),  # anchor-multiple threshold\n",
        "                'anchors': (2, 2.0, 10.0),  # anchors per output grid (0 to ignore)\n",
        "                'fl_gamma': (0, 0.0, 2.0),  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "                'hsv_h': (1, 0.0, 0.1),  # image HSV-Hue augmentation (fraction)\n",
        "                'hsv_s': (1, 0.0, 0.9),  # image HSV-Saturation augmentation (fraction)\n",
        "                'hsv_v': (1, 0.0, 0.9),  # image HSV-Value augmentation (fraction)\n",
        "                'degrees': (1, 0.0, 45.0),  # image rotation (+/- deg)\n",
        "                'translate': (1, 0.0, 0.9),  # image translation (+/- fraction)\n",
        "                'scale': (1, 0.0, 0.9),  # image scale (+/- gain)\n",
        "                'shear': (1, 0.0, 10.0),  # image shear (+/- deg)\n",
        "                'perspective': (0, 0.0, 0.001),  # image perspective (+/- fraction), range 0-0.001\n",
        "                'flipud': (1, 0.0, 1.0),  # image flip up-down (probability)\n",
        "                'fliplr': (0, 0.0, 1.0),  # image flip left-right (probability)\n",
        "                'mosaic': (1, 0.0, 1.0),  # image mixup (probability)\n",
        "                'mixup': (1, 0.0, 1.0),  # image mixup (probability)\n",
        "                'copy_paste': (1, 0.0, 1.0)}  # segment copy-paste (probability)\n",
        "\n",
        "        with open(opt.hyp) as f:\n",
        "            hyp = yaml.safe_load(f)  # load hyps dict\n",
        "            if 'anchors' not in hyp:  # anchors commented in hyp.yaml\n",
        "                hyp['anchors'] = 3\n",
        "        assert LOCAL_RANK == -1, 'DDP mode not implemented for --evolve'\n",
        "        opt.noval, opt.nosave = True, True  # only val/save final epoch\n",
        "        # ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices\n",
        "        yaml_file = Path(opt.save_dir) / 'hyp_evolved.yaml'  # save best result here\n",
        "        if opt.bucket:\n",
        "            os.system('gsutil cp gs://%s/evolve.txt .' % opt.bucket)  # download evolve.txt if exists\n",
        "\n",
        "        for _ in range(opt.evolve):  # generations to evolve\n",
        "            if Path('evolve.txt').exists():  # if evolve.txt exists: select best hyps and mutate\n",
        "                # Select parent(s)\n",
        "                parent = 'single'  # parent selection method: 'single' or 'weighted'\n",
        "                x = np.loadtxt('evolve.txt', ndmin=2)\n",
        "                n = min(5, len(x))  # number of previous results to consider\n",
        "                x = x[np.argsort(-fitness(x))][:n]  # top n mutations\n",
        "                w = fitness(x) - fitness(x).min() + 1E-6  # weights (sum > 0)\n",
        "                if parent == 'single' or len(x) == 1:\n",
        "                    # x = x[random.randint(0, n - 1)]  # random selection\n",
        "                    x = x[random.choices(range(n), weights=w)[0]]  # weighted selection\n",
        "                elif parent == 'weighted':\n",
        "                    x = (x * w.reshape(n, 1)).sum(0) / w.sum()  # weighted combination\n",
        "\n",
        "                # Mutate\n",
        "                mp, s = 0.8, 0.2  # mutation probability, sigma\n",
        "                npr = np.random\n",
        "                npr.seed(int(time.time()))\n",
        "                g = np.array([x[0] for x in meta.values()])  # gains 0-1\n",
        "                ng = len(meta)\n",
        "                v = np.ones(ng)\n",
        "                while all(v == 1):  # mutate until a change occurs (prevent duplicates)\n",
        "                    v = (g * (npr.random(ng) < mp) * npr.randn(ng) * npr.random() * s + 1).clip(0.3, 3.0)\n",
        "                for i, k in enumerate(hyp.keys()):  # plt.hist(v.ravel(), 300)\n",
        "                    hyp[k] = float(x[i + 7] * v[i])  # mutate\n",
        "\n",
        "            # Constrain to limits\n",
        "            for k, v in meta.items():\n",
        "                hyp[k] = max(hyp[k], v[1])  # lower limit\n",
        "                hyp[k] = min(hyp[k], v[2])  # upper limit\n",
        "                hyp[k] = round(hyp[k], 5)  # significant digits\n",
        "\n",
        "            # Train mutation\n",
        "            results = train(hyp.copy(), opt, device)\n",
        "\n",
        "            # Write mutation results\n",
        "            print_mutation(hyp.copy(), results, yaml_file, opt.bucket)\n",
        "\n",
        "        # Plot results\n",
        "        plot_evolution(yaml_file)\n",
        "        print(f'Hyperparameter evolution complete. Best results saved as: {yaml_file}\\n'\n",
        "              f'Command to train a new model with these hyperparameters: $ python train.py --hyp {yaml_file}')\n",
        "\n",
        "\n",
        "def run(**kwargs):\n",
        "    # Usage: import train; train.run(imgsz=320, weights='yolov5m.pt')\n",
        "    opt = parse_opt(True)\n",
        "    for k, v in kwargs.items():\n",
        "        setattr(opt, k, v)\n",
        "    main(opt)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "    main(opt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc_lYwInGNhm"
      },
      "source": [
        "\n",
        "import contextlib\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import platform\n",
        "import random\n",
        "import re\n",
        "import signal\n",
        "import time\n",
        "import urllib\n",
        "from itertools import repeat\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from pathlib import Path\n",
        "from subprocess import check_output\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pkg_resources as pkg\n",
        "import torch\n",
        "import torchvision\n",
        "import yaml\n",
        "\n",
        "from utils.google_utils import gsutil_getsize\n",
        "from utils.metrics import box_iou, fitness\n",
        "from utils.torch_utils import init_torch_seeds\n",
        "\n",
        "# Settings\n",
        "torch.set_printoptions(linewidth=320, precision=5, profile='long')\n",
        "np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # format short g, %precision=5\n",
        "pd.options.display.max_columns = 10\n",
        "cv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)\n",
        "os.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))  # NumExpr max threads\n",
        "\n",
        "\n",
        "class timeout(contextlib.ContextDecorator):\n",
        "    # Usage: @timeout(seconds) decorator or 'with timeout(seconds):' context manager\n",
        "    def __init__(self, seconds, *, timeout_msg='', suppress_timeout_errors=True):\n",
        "        self.seconds = int(seconds)\n",
        "        self.timeout_message = timeout_msg\n",
        "        self.suppress = bool(suppress_timeout_errors)\n",
        "\n",
        "    def _timeout_handler(self, signum, frame):\n",
        "        raise TimeoutError(self.timeout_message)\n",
        "\n",
        "    def __enter__(self):\n",
        "        signal.signal(signal.SIGALRM, self._timeout_handler)  # Set handler for SIGALRM\n",
        "        signal.alarm(self.seconds)  # start countdown for SIGALRM to be raised\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        signal.alarm(0)  # Cancel SIGALRM if it's scheduled\n",
        "        if self.suppress and exc_type is TimeoutError:  # Suppress TimeoutError\n",
        "            return True\n",
        "\n",
        "\n",
        "def set_logging(rank=-1, verbose=True):\n",
        "    logging.basicConfig(\n",
        "        format=\"%(message)s\",\n",
        "        level=logging.INFO if (verbose and rank in [-1, 0]) else logging.WARN)\n",
        "\n",
        "\n",
        "def init_seeds(seed=0):\n",
        "    # Initialize random number generator (RNG) seeds\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    init_torch_seeds(seed)\n",
        "\n",
        "\n",
        "def get_latest_run(search_dir='.'):\n",
        "    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)\n",
        "    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)\n",
        "    return max(last_list, key=os.path.getctime) if last_list else ''\n",
        "\n",
        "\n",
        "def is_docker():\n",
        "    # Is environment a Docker container?\n",
        "    return Path('/workspace').exists()  # or Path('/.dockerenv').exists()\n",
        "\n",
        "\n",
        "def is_colab():\n",
        "    # Is environment a Google Colab instance?\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        return False\n",
        "\n",
        "\n",
        "def is_pip():\n",
        "    # Is file in a pip package?\n",
        "    return 'site-packages' in Path(__file__).absolute().parts\n",
        "\n",
        "\n",
        "def emojis(str=''):\n",
        "    # Return platform-dependent emoji-safe version of string\n",
        "    return str.encode().decode('ascii', 'ignore') if platform.system() == 'Windows' else str\n",
        "\n",
        "\n",
        "def file_size(file):\n",
        "    # Return file size in MB\n",
        "    return Path(file).stat().st_size / 1e6\n",
        "\n",
        "\n",
        "def check_online():\n",
        "    # Check internet connectivity\n",
        "    import socket\n",
        "    try:\n",
        "        socket.create_connection((\"1.1.1.1\", 443), 5)  # check host accessibility\n",
        "        return True\n",
        "    except OSError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def check_git_status(err_msg=', for updates see https://github.com/ultralytics/yolov5'):\n",
        "    # Recommend 'git pull' if code is out of date\n",
        "    print(colorstr('github: '), end='')\n",
        "    try:\n",
        "        assert Path('.git').exists(), 'skipping check (not a git repository)'\n",
        "        assert not is_docker(), 'skipping check (Docker image)'\n",
        "        assert check_online(), 'skipping check (offline)'\n",
        "\n",
        "        cmd = 'git fetch && git config --get remote.origin.url'\n",
        "        url = check_output(cmd, shell=True, timeout=5).decode().strip().rstrip('.git')  # git fetch\n",
        "        branch = check_output('git rev-parse --abbrev-ref HEAD', shell=True).decode().strip()  # checked out\n",
        "        n = int(check_output(f'git rev-list {branch}..origin/master --count', shell=True))  # commits behind\n",
        "        if n > 0:\n",
        "            s = f\" WARNING: code is out of date by {n} commit{'s' * (n > 1)}. \" \\\n",
        "                f\"Use 'git pull' to update or 'git clone {url}' to download latest.\"\n",
        "        else:\n",
        "            s = f'up to date with {url} '\n",
        "        print(emojis(s))  # emoji-safe\n",
        "    except Exception as e:\n",
        "        print(f'{e}{err_msg}')\n",
        "\n",
        "\n",
        "def check_python(minimum='3.6.2'):\n",
        "    # Check current python version vs. required python version\n",
        "    check_version(platform.python_version(), minimum, name='Python ')\n",
        "\n",
        "\n",
        "def check_version(current='0.0.0', minimum='0.0.0', name='version ', pinned=False):\n",
        "    # Check version vs. required version\n",
        "    current, minimum = (pkg.parse_version(x) for x in (current, minimum))\n",
        "    result = (current == minimum) if pinned else (current >= minimum)\n",
        "    assert result, f'{name}{minimum} required by YOLOv5, but {name}{current} is currently installed'\n",
        "\n",
        "\n",
        "def check_requirements(requirements='requirements.txt', exclude=()):\n",
        "    # Check installed dependencies meet requirements (pass *.txt file or list of packages)\n",
        "    prefix = colorstr('red', 'bold', 'requirements:')\n",
        "    check_python()  # check python version\n",
        "    if isinstance(requirements, (str, Path)):  # requirements.txt file\n",
        "        file = Path(requirements)\n",
        "        if not file.exists():\n",
        "            print(f\"{prefix} {file.resolve()} not found, check failed.\")\n",
        "            return\n",
        "        requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(file.open()) if x.name not in exclude]\n",
        "    else:  # list or tuple of packages\n",
        "        requirements = [x for x in requirements if x not in exclude]\n",
        "\n",
        "    n = 0  # number of packages updates\n",
        "    for r in requirements:\n",
        "        try:\n",
        "            pkg.require(r)\n",
        "        except Exception as e:  # DistributionNotFound or VersionConflict if requirements not met\n",
        "            print(f\"{prefix} {r} not found and is required by YOLOv5, attempting auto-update...\")\n",
        "            try:\n",
        "                assert check_online(), f\"'pip install {r}' skipped (offline)\"\n",
        "                print(check_output(f\"pip install '{r}'\", shell=True).decode())\n",
        "                n += 1\n",
        "            except Exception as e:\n",
        "                print(f'{prefix} {e}')\n",
        "\n",
        "    if n:  # if packages updated\n",
        "        source = file.resolve() if 'file' in locals() else requirements\n",
        "        s = f\"{prefix} {n} package{'s' * (n > 1)} updated per {source}\\n\" \\\n",
        "            f\"{prefix}  {colorstr('bold', 'Restart runtime or rerun command for updates to take effect')}\\n\"\n",
        "        print(emojis(s))  # emoji-safe\n",
        "\n",
        "\n",
        "def check_img_size(img_size, s=32):\n",
        "    # Verify img_size is a multiple of stride s\n",
        "    new_size = make_divisible(img_size, int(s))  # ceil gs-multiple\n",
        "    if new_size != img_size:\n",
        "        print('WARNING: --img-size %g must be multiple of max stride %g, updating to %g' % (img_size, s, new_size))\n",
        "    return new_size\n",
        "\n",
        "\n",
        "def check_imshow():\n",
        "    # Check if environment supports image displays\n",
        "    try:\n",
        "        assert not is_docker(), 'cv2.imshow() is disabled in Docker environments'\n",
        "        assert not is_colab(), 'cv2.imshow() is disabled in Google Colab environments'\n",
        "        cv2.imshow('test', np.zeros((1, 1, 3)))\n",
        "        cv2.waitKey(1)\n",
        "        cv2.destroyAllWindows()\n",
        "        cv2.waitKey(1)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f'WARNING: Environment does not support cv2.imshow() or PIL Image.show() image displays\\n{e}')\n",
        "        return False\n",
        "\n",
        "\n",
        "def check_file(file):\n",
        "    # Search/download file (if necessary) and return path\n",
        "    file = str(file)  # convert to str()\n",
        "    if Path(file).is_file() or file == '':  # exists\n",
        "        return file\n",
        "    elif file.startswith(('http:/', 'https:/')):  # download\n",
        "        url = str(Path(file)).replace(':/', '://')  # Pathlib turns :// -> :/\n",
        "        file = Path(urllib.parse.unquote(file)).name.split('?')[0]  # '%2F' to '/', split https://url.com/file.txt?auth\n",
        "        print(f'Downloading {url} to {file}...')\n",
        "        torch.hub.download_url_to_file(url, file)\n",
        "        assert Path(file).exists() and Path(file).stat().st_size > 0, f'File download failed: {url}'  # check\n",
        "        return file\n",
        "    else:  # search\n",
        "        files = glob.glob('./**/' + file, recursive=True)  # find file\n",
        "        assert len(files), f'File not found: {file}'  # assert file was found\n",
        "        assert len(files) == 1, f\"Multiple files match '{file}', specify exact path: {files}\"  # assert unique\n",
        "        return files[0]  # return file\n",
        "\n",
        "\n",
        "def check_dataset(data, autodownload=True):\n",
        "    # Download dataset if not found locally\n",
        "    path = Path(data.get('path', ''))  # optional 'path' field\n",
        "    if path:\n",
        "        for k in 'train', 'val', 'test':\n",
        "            if data.get(k):  # prepend path\n",
        "                data[k] = str(path / data[k]) if isinstance(data[k], str) else [str(path / x) for x in data[k]]\n",
        "\n",
        "    train, val, test, s = [data.get(x) for x in ('train', 'val', 'test', 'download')]\n",
        "    if val:\n",
        "        val = [Path(x).resolve() for x in (val if isinstance(val, list) else [val])]  # val path\n",
        "        if not all(x.exists() for x in val):\n",
        "            print('\\nWARNING: Dataset not found, nonexistent paths: %s' % [str(x) for x in val if not x.exists()])\n",
        "            if s and autodownload:  # download script\n",
        "                if s.startswith('http') and s.endswith('.zip'):  # URL\n",
        "                    f = Path(s).name  # filename\n",
        "                    print(f'Downloading {s} ...')\n",
        "                    torch.hub.download_url_to_file(s, f)\n",
        "                    root = path.parent if 'path' in data else '..'  # unzip directory i.e. '../'\n",
        "                    Path(root).mkdir(parents=True, exist_ok=True)  # create root\n",
        "                    r = os.system(f'unzip -q {f} -d {root} && rm {f}')  # unzip\n",
        "                elif s.startswith('bash '):  # bash script\n",
        "                    print(f'Running {s} ...')\n",
        "                    r = os.system(s)\n",
        "                else:  # python script\n",
        "                    r = exec(s, {'yaml': data})  # return None\n",
        "                print('Dataset autodownload %s\\n' % ('success' if r in (0, None) else 'failure'))  # print result\n",
        "            else:\n",
        "                raise Exception('Dataset not found.')\n",
        "\n",
        "\n",
        "def download(url, dir='.', unzip=True, delete=True, curl=False, threads=1):\n",
        "    # Multi-threaded file download and unzip function\n",
        "    def download_one(url, dir):\n",
        "        # Download 1 file\n",
        "        f = dir / Path(url).name  # filename\n",
        "        if not f.exists():\n",
        "            print(f'Downloading {url} to {f}...')\n",
        "            if curl:\n",
        "                os.system(f\"curl -L '{url}' -o '{f}' --retry 9 -C -\")  # curl download, retry and resume on fail\n",
        "            else:\n",
        "                torch.hub.download_url_to_file(url, f, progress=True)  # torch download\n",
        "        if unzip and f.suffix in ('.zip', '.gz'):\n",
        "            print(f'Unzipping {f}...')\n",
        "            if f.suffix == '.zip':\n",
        "                s = f'unzip -qo {f} -d {dir}'  # unzip -quiet -overwrite\n",
        "            elif f.suffix == '.gz':\n",
        "                s = f'tar xfz {f} --directory {f.parent}'  # unzip\n",
        "            if delete:  # delete zip file after unzip\n",
        "                s += f' && rm {f}'\n",
        "            os.system(s)\n",
        "\n",
        "    dir = Path(dir)\n",
        "    dir.mkdir(parents=True, exist_ok=True)  # make directory\n",
        "    if threads > 1:\n",
        "        pool = ThreadPool(threads)\n",
        "        pool.imap(lambda x: download_one(*x), zip(url, repeat(dir)))  # multi-threaded\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "    else:\n",
        "        for u in tuple(url) if isinstance(url, str) else url:\n",
        "            download_one(u, dir)\n",
        "\n",
        "\n",
        "def make_divisible(x, divisor):\n",
        "    # Returns x evenly divisible by divisor\n",
        "    return math.ceil(x / divisor) * divisor\n",
        "\n",
        "\n",
        "def clean_str(s):\n",
        "    # Cleans a string by replacing special characters with underscore _\n",
        "    return re.sub(pattern=\"[|@#!$%&()=?^*;:,><+]\", repl=\"_\", string=s)\n",
        "\n",
        "\n",
        "def one_cycle(y1=0.0, y2=1.0, steps=100):\n",
        "    # lambda function for sinusoidal ramp from y1 to y2\n",
        "    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\n",
        "\n",
        "\n",
        "def colorstr(*input):\n",
        "    # Colors a string https://en.wikipedia.org/wiki/ANSI_escape_code, i.e.  colorstr('blue', 'hello world')\n",
        "    *args, string = input if len(input) > 1 else ('blue', 'bold', input[0])  # color arguments, string\n",
        "    colors = {'black': '\\033[30m',  # basic colors\n",
        "              'red': '\\033[31m',\n",
        "              'green': '\\033[32m',\n",
        "              'yellow': '\\033[33m',\n",
        "              'blue': '\\033[34m',\n",
        "              'magenta': '\\033[35m',\n",
        "              'cyan': '\\033[36m',\n",
        "              'white': '\\033[37m',\n",
        "              'bright_black': '\\033[90m',  # bright colors\n",
        "              'bright_red': '\\033[91m',\n",
        "              'bright_green': '\\033[92m',\n",
        "              'bright_yellow': '\\033[93m',\n",
        "              'bright_blue': '\\033[94m',\n",
        "              'bright_magenta': '\\033[95m',\n",
        "              'bright_cyan': '\\033[96m',\n",
        "              'bright_white': '\\033[97m',\n",
        "              'end': '\\033[0m',  # misc\n",
        "              'bold': '\\033[1m',\n",
        "              'underline': '\\033[4m'}\n",
        "    return ''.join(colors[x] for x in args) + f'{string}' + colors['end']\n",
        "\n",
        "\n",
        "def labels_to_class_weights(labels, nc=80):\n",
        "    # Get class weights (inverse frequency) from training labels\n",
        "    if labels[0] is None:  # no labels loaded\n",
        "        return torch.Tensor()\n",
        "\n",
        "    labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO\n",
        "    classes = labels[:, 0].astype(np.int)  # labels = [class xywh]\n",
        "    weights = np.bincount(classes, minlength=nc)  # occurrences per class\n",
        "\n",
        "    # Prepend gridpoint count (for uCE training)\n",
        "    # gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image\n",
        "    # weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start\n",
        "\n",
        "    weights[weights == 0] = 1  # replace empty bins with 1\n",
        "    weights = 1 / weights  # number of targets per class\n",
        "    weights /= weights.sum()  # normalize\n",
        "    return torch.from_numpy(weights)\n",
        "\n",
        "\n",
        "def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):\n",
        "    # Produces image weights based on class_weights and image contents\n",
        "    class_counts = np.array([np.bincount(x[:, 0].astype(np.int), minlength=nc) for x in labels])\n",
        "    image_weights = (class_weights.reshape(1, nc) * class_counts).sum(1)\n",
        "    # index = random.choices(range(n), weights=image_weights, k=1)  # weight image sample\n",
        "    return image_weights\n",
        "\n",
        "\n",
        "def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)\n",
        "    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
        "    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n",
        "    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')\n",
        "    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco\n",
        "    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet\n",
        "    x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,\n",
        "         35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n",
        "         64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]\n",
        "    return x\n",
        "\n",
        "\n",
        "def xyxy2xywh(x):\n",
        "    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where xy1=top-left, xy2=bottom-right\n",
        "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
        "    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # x center\n",
        "    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # y center\n",
        "    y[:, 2] = x[:, 2] - x[:, 0]  # width\n",
        "    y[:, 3] = x[:, 3] - x[:, 1]  # height\n",
        "    return y\n",
        "\n",
        "\n",
        "def xywh2xyxy(x):\n",
        "    # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
        "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
        "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
        "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
        "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
        "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
        "    return y\n",
        "\n",
        "\n",
        "def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n",
        "    # Convert nx4 boxes from [x, y, w, h] normalized to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n",
        "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
        "    y[:, 0] = w * (x[:, 0] - x[:, 2] / 2) + padw  # top left x\n",
        "    y[:, 1] = h * (x[:, 1] - x[:, 3] / 2) + padh  # top left y\n",
        "    y[:, 2] = w * (x[:, 0] + x[:, 2] / 2) + padw  # bottom right x\n",
        "    y[:, 3] = h * (x[:, 1] + x[:, 3] / 2) + padh  # bottom right y\n",
        "    return y\n",
        "\n",
        "\n",
        "def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):\n",
        "    # Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] normalized where xy1=top-left, xy2=bottom-right\n",
        "    if clip:\n",
        "        clip_coords(x, (h - eps, w - eps))  # warning: inplace clip\n",
        "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
        "    y[:, 0] = ((x[:, 0] + x[:, 2]) / 2) / w  # x center\n",
        "    y[:, 1] = ((x[:, 1] + x[:, 3]) / 2) / h  # y center\n",
        "    y[:, 2] = (x[:, 2] - x[:, 0]) / w  # width\n",
        "    y[:, 3] = (x[:, 3] - x[:, 1]) / h  # height\n",
        "    return y\n",
        "\n",
        "\n",
        "def xyn2xy(x, w=640, h=640, padw=0, padh=0):\n",
        "    # Convert normalized segments into pixel segments, shape (n,2)\n",
        "    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n",
        "    y[:, 0] = w * x[:, 0] + padw  # top left x\n",
        "    y[:, 1] = h * x[:, 1] + padh  # top left y\n",
        "    return y\n",
        "\n",
        "\n",
        "def segment2box(segment, width=640, height=640):\n",
        "    # Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to (xyxy)\n",
        "    x, y = segment.T  # segment xy\n",
        "    inside = (x >= 0) & (y >= 0) & (x <= width) & (y <= height)\n",
        "    x, y, = x[inside], y[inside]\n",
        "    return np.array([x.min(), y.min(), x.max(), y.max()]) if any(x) else np.zeros((1, 4))  # xyxy\n",
        "\n",
        "\n",
        "def segments2boxes(segments):\n",
        "    # Convert segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)\n",
        "    boxes = []\n",
        "    for s in segments:\n",
        "        x, y = s.T  # segment xy\n",
        "        boxes.append([x.min(), y.min(), x.max(), y.max()])  # cls, xyxy\n",
        "    return xyxy2xywh(np.array(boxes))  # cls, xywh\n",
        "\n",
        "\n",
        "def resample_segments(segments, n=1000):\n",
        "    # Up-sample an (n,2) segment\n",
        "    for i, s in enumerate(segments):\n",
        "        x = np.linspace(0, len(s) - 1, n)\n",
        "        xp = np.arange(len(s))\n",
        "        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy\n",
        "    return segments\n",
        "\n",
        "\n",
        "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
        "    # Rescale coords (xyxy) from img1_shape to img0_shape\n",
        "    if ratio_pad is None:  # calculate from img0_shape\n",
        "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
        "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
        "    else:\n",
        "        gain = ratio_pad[0][0]\n",
        "        pad = ratio_pad[1]\n",
        "\n",
        "    coords[:, [0, 2]] -= pad[0]  # x padding\n",
        "    coords[:, [1, 3]] -= pad[1]  # y padding\n",
        "    coords[:, :4] /= gain\n",
        "    clip_coords(coords, img0_shape)\n",
        "    return coords\n",
        "\n",
        "\n",
        "def clip_coords(boxes, shape):\n",
        "    # Clip bounding xyxy bounding boxes to image shape (height, width)\n",
        "    if isinstance(boxes, torch.Tensor):  # faster individually\n",
        "        boxes[:, 0].clamp_(0, shape[1])  # x1\n",
        "        boxes[:, 1].clamp_(0, shape[0])  # y1\n",
        "        boxes[:, 2].clamp_(0, shape[1])  # x2\n",
        "        boxes[:, 3].clamp_(0, shape[0])  # y2\n",
        "    else:  # np.array (faster grouped)\n",
        "        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # x1, x2\n",
        "        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # y1, y2\n",
        "\n",
        "\n",
        "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None, agnostic=False, multi_label=False,\n",
        "                        labels=(), max_det=300):\n",
        "    \"\"\"Runs Non-Maximum Suppression (NMS) on inference results\n",
        "\n",
        "    Returns:\n",
        "         list of detections, on (n,6) tensor per image [xyxy, conf, cls]\n",
        "    \"\"\"\n",
        "\n",
        "    nc = prediction.shape[2] - 5  # number of classes\n",
        "    xc = prediction[..., 4] > conf_thres  # candidates\n",
        "\n",
        "    # Checks\n",
        "    assert 0 <= conf_thres <= 1, f'Invalid Confidence threshold {conf_thres}, valid values are between 0.0 and 1.0'\n",
        "    assert 0 <= iou_thres <= 1, f'Invalid IoU {iou_thres}, valid values are between 0.0 and 1.0'\n",
        "\n",
        "    # Settings\n",
        "    min_wh, max_wh = 2, 4096  # (pixels) minimum and maximum box width and height\n",
        "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
        "    time_limit = 10.0  # seconds to quit after\n",
        "    redundant = True  # require redundant detections\n",
        "    multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
        "    merge = False  # use merge-NMS\n",
        "\n",
        "    t = time.time()\n",
        "    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
        "    for xi, x in enumerate(prediction):  # image index, image inference\n",
        "        # Apply constraints\n",
        "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
        "        x = x[xc[xi]]  # confidence\n",
        "\n",
        "        # Cat apriori labels if autolabelling\n",
        "        if labels and len(labels[xi]):\n",
        "            l = labels[xi]\n",
        "            v = torch.zeros((len(l), nc + 5), device=x.device)\n",
        "            v[:, :4] = l[:, 1:5]  # box\n",
        "            v[:, 4] = 1.0  # conf\n",
        "            v[range(len(l)), l[:, 0].long() + 5] = 1.0  # cls\n",
        "            x = torch.cat((x, v), 0)\n",
        "\n",
        "        # If none remain process next image\n",
        "        if not x.shape[0]:\n",
        "            continue\n",
        "\n",
        "        # Compute conf\n",
        "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
        "\n",
        "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
        "        box = xywh2xyxy(x[:, :4])\n",
        "\n",
        "        # Detections matrix nx6 (xyxy, conf, cls)\n",
        "        if multi_label:\n",
        "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
        "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
        "        else:  # best class only\n",
        "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
        "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
        "\n",
        "        # Filter by class\n",
        "        if classes is not None:\n",
        "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
        "\n",
        "        # Apply finite constraint\n",
        "        # if not torch.isfinite(x).all():\n",
        "        #     x = x[torch.isfinite(x).all(1)]\n",
        "\n",
        "        # Check shape\n",
        "        n = x.shape[0]  # number of boxes\n",
        "        if not n:  # no boxes\n",
        "            continue\n",
        "        elif n > max_nms:  # excess boxes\n",
        "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]  # sort by confidence\n",
        "\n",
        "        # Batched NMS\n",
        "        c = x[:, 5:6] * (0 if agnostic else max_wh)  # classes\n",
        "        boxes, scores = x[:, :4] + c, x[:, 4]  # boxes (offset by class), scores\n",
        "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
        "        if i.shape[0] > max_det:  # limit detections\n",
        "            i = i[:max_det]\n",
        "        if merge and (1 < n < 3E3):  # Merge NMS (boxes merged using weighted mean)\n",
        "            # update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)\n",
        "            iou = box_iou(boxes[i], boxes) > iou_thres  # iou matrix\n",
        "            weights = iou * scores[None]  # box weights\n",
        "            x[i, :4] = torch.mm(weights, x[:, :4]).float() / weights.sum(1, keepdim=True)  # merged boxes\n",
        "            if redundant:\n",
        "                i = i[iou.sum(1) > 1]  # require redundancy\n",
        "\n",
        "        output[xi] = x[i]\n",
        "        if (time.time() - t) > time_limit:\n",
        "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
        "            break  # time limit exceeded\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def strip_optimizer(f='best.pt', s=''):  # from utils.general import *; strip_optimizer()\n",
        "    # Strip optimizer from 'f' to finalize training, optionally save as 's'\n",
        "    x = torch.load(f, map_location=torch.device('cpu'))\n",
        "    if x.get('ema'):\n",
        "        x['model'] = x['ema']  # replace model with ema\n",
        "    for k in 'optimizer', 'training_results', 'wandb_id', 'ema', 'updates':  # keys\n",
        "        x[k] = None\n",
        "    x['epoch'] = -1\n",
        "    x['model'].half()  # to FP16\n",
        "    for p in x['model'].parameters():\n",
        "        p.requires_grad = False\n",
        "    torch.save(x, s or f)\n",
        "    mb = os.path.getsize(s or f) / 1E6  # filesize\n",
        "    print(f\"Optimizer stripped from {f},{(' saved as %s,' % s) if s else ''} {mb:.1f}MB\")\n",
        "\n",
        "\n",
        "def print_mutation(hyp, results, yaml_file='hyp_evolved.yaml', bucket=''):\n",
        "    # Print mutation results to evolve.txt (for use with train.py --evolve)\n",
        "    a = '%10s' * len(hyp) % tuple(hyp.keys())  # hyperparam keys\n",
        "    b = '%10.3g' * len(hyp) % tuple(hyp.values())  # hyperparam values\n",
        "    c = '%10.4g' * len(results) % results  # results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)\n",
        "    print('\\n%s\\n%s\\nEvolved fitness: %s\\n' % (a, b, c))\n",
        "\n",
        "    if bucket:\n",
        "        url = 'gs://%s/evolve.txt' % bucket\n",
        "        if gsutil_getsize(url) > (os.path.getsize('evolve.txt') if os.path.exists('evolve.txt') else 0):\n",
        "            os.system('gsutil cp %s .' % url)  # download evolve.txt if larger than local\n",
        "\n",
        "    with open('evolve.txt', 'a') as f:  # append result\n",
        "        f.write(c + b + '\\n')\n",
        "    x = np.unique(np.loadtxt('evolve.txt', ndmin=2), axis=0)  # load unique rows\n",
        "    x = x[np.argsort(-fitness(x))]  # sort\n",
        "    np.savetxt('evolve.txt', x, '%10.3g')  # save sort by fitness\n",
        "\n",
        "    # Save yaml\n",
        "    for i, k in enumerate(hyp.keys()):\n",
        "        hyp[k] = float(x[0, i + 7])\n",
        "    with open(yaml_file, 'w') as f:\n",
        "        results = tuple(x[0, :7])\n",
        "        c = '%10.4g' * len(results) % results  # results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)\n",
        "        f.write('# Hyperparameter Evolution Results\\n# Generations: %g\\n# Metrics: ' % len(x) + c + '\\n\\n')\n",
        "        yaml.safe_dump(hyp, f, sort_keys=False)\n",
        "\n",
        "    if bucket:\n",
        "        os.system('gsutil cp evolve.txt %s gs://%s' % (yaml_file, bucket))  # upload\n",
        "\n",
        "\n",
        "def apply_classifier(x, model, img, im0):\n",
        "    # Apply a second stage classifier to yolo outputs\n",
        "    im0 = [im0] if isinstance(im0, np.ndarray) else im0\n",
        "    for i, d in enumerate(x):  # per image\n",
        "        if d is not None and len(d):\n",
        "            d = d.clone()\n",
        "\n",
        "            # Reshape and pad cutouts\n",
        "            b = xyxy2xywh(d[:, :4])  # boxes\n",
        "            b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # rectangle to square\n",
        "            b[:, 2:] = b[:, 2:] * 1.3 + 30  # pad\n",
        "            d[:, :4] = xywh2xyxy(b).long()\n",
        "\n",
        "            # Rescale boxes from img_size to im0 size\n",
        "            scale_coords(img.shape[2:], d[:, :4], im0[i].shape)\n",
        "\n",
        "            # Classes\n",
        "            pred_cls1 = d[:, 5].long()\n",
        "            ims = []\n",
        "            for j, a in enumerate(d):  # per item\n",
        "                cutout = im0[i][int(a[1]):int(a[3]), int(a[0]):int(a[2])]\n",
        "                im = cv2.resize(cutout, (224, 224))  # BGR\n",
        "                # cv2.imwrite('example%i.jpg' % j, cutout)\n",
        "\n",
        "                im = im[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
        "                im = np.ascontiguousarray(im, dtype=np.float32)  # uint8 to float32\n",
        "                im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "                ims.append(im)\n",
        "\n",
        "            pred_cls2 = model(torch.Tensor(ims).to(d.device)).argmax(1)  # classifier prediction\n",
        "            x[i] = x[i][pred_cls1 == pred_cls2]  # retain matching class detections\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def save_one_box(xyxy, im, file='image.jpg', gain=1.02, pad=10, square=False, BGR=False, save=True):\n",
        "    # Save image crop as {file} with crop size multiple {gain} and {pad} pixels. Save and/or return crop\n",
        "    xyxy = torch.tensor(xyxy).view(-1, 4)\n",
        "    b = xyxy2xywh(xyxy)  # boxes\n",
        "    if square:\n",
        "        b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # attempt rectangle to square\n",
        "    b[:, 2:] = b[:, 2:] * gain + pad  # box wh * gain + pad\n",
        "    xyxy = xywh2xyxy(b).long()\n",
        "    clip_coords(xyxy, im.shape)\n",
        "    crop = im[int(xyxy[0, 1]):int(xyxy[0, 3]), int(xyxy[0, 0]):int(xyxy[0, 2]), ::(1 if BGR else -1)]\n",
        "    path=str(increment_path(file, mkdir=True).with_suffix('.jpg'))\n",
        "    print(path+'\\n')\n",
        "    cv2.imwrite(path, crop)\n",
        "    return crop\n",
        "\n",
        "\n",
        "def increment_path(path, exist_ok=False, sep='', mkdir=False):\n",
        "    # Increment file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.\n",
        "    path = Path(path)  # os-agnostic\n",
        "    if path.exists() and not exist_ok:\n",
        "        suffix = path.suffix\n",
        "        path = path.with_suffix('')\n",
        "        dirs = glob.glob(f\"{path}{sep}*\")  # similar paths\n",
        "        matches = [re.search(rf\"%s{sep}(\\d+)\" % path.stem, d) for d in dirs]\n",
        "        i = [int(m.groups()[0]) for m in matches if m]  # indices\n",
        "        n = max(i) + 1 if i else 2  # increment number\n",
        "        path = '/content/gdrive/MyDrive/predictions/'+str(n)  # update path\n",
        "    dir = path if path.suffix == '' else path.parent  # directory\n",
        "    if not dir.exists() and mkdir:\n",
        "        dir.mkdir(parents=True, exist_ok=True)  # make directory\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ewhUbrqGNeu"
      },
      "source": [
        "%%writefile detect.py\n",
        "import argparse\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "FILE = Path(__file__).absolute()\n",
        "sys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path\n",
        "\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, colorstr, non_max_suppression, \\\n",
        "    apply_classifier, scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path, save_one_box\n",
        "from utils.plots import colors, plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run(weights='yolov5s.pt',  # model.pt path(s)\n",
        "        source='data/images',  # file/dir/URL/glob, 0 for webcam\n",
        "        imgsz=640,  # inference size (pixels)\n",
        "        conf_thres=0.25,  # confidence threshold\n",
        "        iou_thres=0.45,  # NMS IOU threshold\n",
        "        max_det=1000,  # maximum detections per image\n",
        "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
        "        view_img=False,  # show results\n",
        "        save_txt=False,  # save results to *.txt\n",
        "        save_conf=False,  # save confidences in --save-txt labels\n",
        "        save_crop=False,  # save cropped prediction boxes\n",
        "        nosave=False,  # do not save images/videos\n",
        "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
        "        agnostic_nms=False,  # class-agnostic NMS\n",
        "        augment=False,  # augmented inference\n",
        "        visualize=False,  # visualize features\n",
        "        update=False,  # update all models\n",
        "        project='runs/detect',  # save results to project/name\n",
        "        name='exp',  # save results to project/name\n",
        "        exist_ok=False,  # existing project/name ok, do not increment\n",
        "        line_thickness=3,  # bounding box thickness (pixels)\n",
        "        hide_labels=False,  # hide labels\n",
        "        hide_conf=False,  # hide confidences\n",
        "        half=False,  # use FP16 half-precision inference\n",
        "        ):\n",
        "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
        "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
        "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
        "\n",
        "    # Directories\n",
        "    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run\n",
        "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
        "\n",
        "    # Initialize\n",
        "    set_logging()\n",
        "    device = select_device(device)\n",
        "    half &= device.type != 'cpu'  # half precision only supported on CUDA\n",
        "\n",
        "    # Load model\n",
        "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
        "    names = model.module.names if hasattr(model, 'module') else model.names  # get class names\n",
        "    if half:\n",
        "        model.half()  # to FP16\n",
        "\n",
        "    # Second-stage classifier\n",
        "    classify = False\n",
        "    if classify:\n",
        "        modelc = load_classifier(name='resnet50', n=2)  # initialize\n",
        "        modelc.load_state_dict(torch.load('resnet50.pt', map_location=device)['model']).to(device).eval()\n",
        "\n",
        "    # Dataloader\n",
        "    if webcam:\n",
        "        view_img = check_imshow()\n",
        "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
        "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
        "        bs = len(dataset)  # batch_size\n",
        "    else:\n",
        "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "        bs = 1  # batch_size\n",
        "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
        "\n",
        "    # Run inference\n",
        "    if device.type != 'cpu':\n",
        "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
        "    t0 = time.time()\n",
        "    for path, img, im0s, vid_cap in dataset:\n",
        "        all_total=[]\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if img.ndimension() == 3:\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "        # Inference\n",
        "        pred = model(img,\n",
        "                     augment=augment,\n",
        "                     visualize=increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False)[0]\n",
        "        # Apply NMS\n",
        "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
        "        \n",
        "\n",
        "        # Apply Classifier\n",
        "        if classify:\n",
        "            pred = apply_classifier(pred, modelc, img, im0s)\n",
        "\n",
        "        # Process detections\n",
        "        for i, det in enumerate(pred):  # detections per image\n",
        "            if webcam:  # batch_size >= 1\n",
        "                p, s, im0, frame = path[i], f'{i}: ', im0s[i].copy(), dataset.count\n",
        "            else:\n",
        "                p, s, im0, frame = path, '', im0s.copy(), getattr(dataset, 'frame', 0)\n",
        "\n",
        "            p = Path(p)  # to Path\n",
        "            save_path = str(Path('/content/gdrive/MyDrive/predictions') / p.name)  # img.jpg\n",
        "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
        "            s += '%gx%g ' % img.shape[2:]  # print string\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
        "            if len(det):\n",
        "                # Rescale boxes from img_size to im0 size\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "\n",
        "                # Print results\n",
        "                for c in det[:, -1].unique():\n",
        "                    n = (det[:, -1] == c).sum()  # detections per class\n",
        "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
        "\n",
        "                # Write results\n",
        "                for *xyxy, conf, cls in reversed(det):\n",
        "                    if save_txt:  # Write to file\n",
        "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
        "                        with open(txt_path + '.txt', 'a') as f:\n",
        "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
        "\n",
        "                    if save_img or save_crop or view_img:  # Add bbox to image\n",
        "                        c = int(cls)  # integer class\n",
        "                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
        "                        x1,y1,x2,y2 = int(xyxy[0].cpu().numpy().item()), int(xyxy[1].cpu().numpy().item()), int(xyxy[2].cpu().numpy().item()), int(xyxy[3].cpu().numpy().item())\n",
        "                        a=imgsz-x2\n",
        "                        b=imgsz-x1\n",
        "                        x1=a\n",
        "                        x2=b\n",
        "                        total=[x1,y1,x2,y2]\n",
        "#                         colors_tot=(np.mean(im0[c1[0]:c2[0],c1[1]:c2[1],0]),\n",
        "#                                     np.mean(im0[c1[0]:c2[0],c1[1]:c2[1],1]),\n",
        "#                                     np.mean(im0[c1[0]:c2[0],c1[1]:c2[1],2]))\n",
        "                        \n",
        "                        if label!=None:\n",
        "                            all_total.append({\n",
        "                            'boxes': total,\n",
        "                            'scores': label})\n",
        "        np.save(path.split('/')[-1].split('.')[0]+'_1'+weights[0].split('/')[-1].split('.')[0]+'.npy',all_total)\n",
        "\n",
        "    if save_txt or save_img:\n",
        "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
        "        print(f\"Results saved to {save_dir}{s}\")\n",
        "\n",
        "    if update:\n",
        "        strip_optimizer(weights)  # update model (to fix SourceChangeWarning)\n",
        "\n",
        "\n",
        "\n",
        "def parse_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', nargs='+', type=str, default='yolov5s.pt', help='model.pt path(s)')\n",
        "    parser.add_argument('--source', type=str, default='data/images', help='file/dir/URL/glob, 0 for webcam')\n",
        "    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')\n",
        "    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--view-img', action='store_true', help='show results')\n",
        "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')\n",
        "    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
        "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n",
        "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--visualize', action='store_true', help='visualize features')\n",
        "    parser.add_argument('--update', action='store_true', help='update all models')\n",
        "    parser.add_argument('--project', default='runs/detect', help='save results to project/name')\n",
        "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')\n",
        "    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')\n",
        "    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')\n",
        "    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')\n",
        "    opt = parser.parse_args()\n",
        "    return opt\n",
        "\n",
        "\n",
        "def main(opt):\n",
        "    check_requirements(exclude=('tensorboard', 'thop'))\n",
        "    run(**vars(opt))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "    main(opt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by_pZoWfGNb6"
      },
      "source": [
        "!python detect.py --source /kaggle/input/hardhat-total/hardhat  --weights /kaggle/input/test-images/last_1.pt --conf 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0w1amVgGNY2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIfUv4qsGNV-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_zX0_zGNS-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}