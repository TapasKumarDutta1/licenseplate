{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "single_pred",
      "provenance": [],
      "authorship_tag": "ABX9TyMyPbhYywtQw318xnpeN30j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/licenseplate/blob/main/single_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFk7fmtSNDSw"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path\n",
        "from xml.dom.minidom import parse\n",
        "from shutil import copyfile\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lfc5AS4NHOa"
      },
      "source": [
        "!mkdir -p Dataset/labels\n",
        "!mkdir -p Dataset/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSuaMwnfNHL_"
      },
      "source": [
        "classes = ['license_plate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFQhdHuNHJP"
      },
      "source": [
        "def convert_annot(size , box):\n",
        "    x1 = int(box[0])\n",
        "    y1 = int(box[1])\n",
        "    x2 = int(box[2])\n",
        "    y2 = int(box[3])\n",
        "\n",
        "    dw = np.float32(1. / int(size[0]))\n",
        "    dh = np.float32(1. / int(size[1]))\n",
        "\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    x = x1 + (w / 2)\n",
        "    y = y1 + (h / 2)\n",
        "\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return [x, y, w, h]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHqVXFLYNHGb"
      },
      "source": [
        "classes = ['license_plate']\n",
        "def convert_annot(size , box):\n",
        "    x1 = int(box[0])\n",
        "    y1 = int(box[1])\n",
        "    x2 = int(box[2])\n",
        "    y2 = int(box[3])\n",
        "\n",
        "#     dw = np.float32(1. / int(size[0]))\n",
        "#     dh = np.float32(1. / int(size[1]))\n",
        "    dw=1\n",
        "    dh=1\n",
        "    \n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    x = x1 + (w / 2)\n",
        "    y = y1 + (h / 2)\n",
        "\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return [x, y, w, h]\n",
        "def save_txt_file(img_jpg_file_name, size, img_box):\n",
        "    save_file_name = '/kaggle/working/Dataset/labels/' +  img_jpg_file_name + '.npy'\n",
        "    #file_path = open(save_file_name, \"a+\")\n",
        "    total=[]\n",
        "    for box in img_box:\n",
        "            cls_num = classes.index(box[0])\n",
        "            total.append([cls_num,int(box[1]),int(box[2]),int(box[3]),int(box[4])])\n",
        "    np.save(save_file_name,total)\n",
        "def get_xml_data(file_path, img_xml_file):\n",
        "    img_path = file_path + '/' + img_xml_file + '.xml'\n",
        "    #print(img_path)\n",
        "\n",
        "    dom = parse(img_path)\n",
        "    root = dom.documentElement\n",
        "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
        "    img_size = root.getElementsByTagName(\"size\")[0]\n",
        "    objects = root.getElementsByTagName(\"object\")\n",
        "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
        "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
        "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
        "   \n",
        "    img_box = []\n",
        "    for box in objects:\n",
        "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
        "        if cls_name=='license_plate':\n",
        "            x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
        "            y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
        "            x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
        "            y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
        "            area=(y2-y1)*(x2-x1)\n",
        "            if (area>10) & (area<20000):\n",
        "                img_jpg_file_name = img_xml_file + '.jpg'\n",
        "                img_box.append([cls_name, x1, x2,y1 , y2])\n",
        "\n",
        "    # test_dataset_box_feature(img_jpg_file_name, img_box)\n",
        "    save_txt_file(img_xml_file, [img_w, img_h], img_box)\n",
        "    return len(img_box)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpJyzt9jNHDr"
      },
      "source": [
        "!ls /kaggle/working/Dataset/labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCWkJRj-NHA-"
      },
      "source": [
        "files = os.listdir('/kaggle/input/number-plates/VOC2007/Annotations')\n",
        "for file in files:\n",
        "    file_xml = file.split(\".\")\n",
        "    get_xml_data('/kaggle/input/number-plates/VOC2007/Annotations', file_xml[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Wl0xiSNG-h"
      },
      "source": [
        "test=[]\n",
        "tst=open('/kaggle/input/number-plates/VOC2007/ImageSets/Main/test.txt').readlines()\n",
        "for i in tst:\n",
        "    test.append(i.split('\\n')[0].split('_')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWPW04OyNG7S"
      },
      "source": [
        "def copy_data(file_list, img_labels_root, imgs_source, mode):\n",
        "\n",
        "    root_file = Path( '/kaggle/working/Dataset/images/'+  mode)\n",
        "    if not root_file.exists():\n",
        "        print(f\"Path {root_file} does not exit\")\n",
        "        os.makedirs(root_file)\n",
        "\n",
        "    root_file = Path('/kaggle/working/Dataset/labels/' + mode)\n",
        "    if not root_file.exists():\n",
        "        print(f\"Path {root_file} does not exit\")\n",
        "        os.makedirs(root_file)\n",
        "\n",
        "    for file in file_list:               \n",
        "        img_name = file.replace('.png', '')        \n",
        "        img_src_file = imgs_source + '/'+'car_' + img_name + '.jpg'        \n",
        "        label_src_file = img_labels_root + '/'+'car_' + img_name + '.txt'\n",
        "\n",
        "        #print(img_sor_file)\n",
        "        #print(label_sor_file)\n",
        "        # im = Image.open(rf\"{img_sor_file}\")\n",
        "        # im.show()\n",
        "\n",
        "        # Copy image\n",
        "        DICT_DIR = '/kaggle/working/Dataset/images/'  + mode\n",
        "        img_dict_file = DICT_DIR + '/' + img_name + '.png'\n",
        "\n",
        "        copyfile(img_src_file, img_dict_file)\n",
        "\n",
        "        # Copy label\n",
        "        DICT_DIR = '/kaggle/working/Dataset/labels/' + mode\n",
        "        img_dict_file = DICT_DIR + '/' + img_name + '.txt'\n",
        "        copyfile(label_src_file, img_dict_file)\n",
        "copy_data(test,  '/kaggle/working/Dataset/labels', '/kaggle/input/number-plates/VOC2007/JPEGImages', \"test\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX7_88HRNG4H"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuc7mVjKNG1a"
      },
      "source": [
        "def convert_annot(size , box):\n",
        "    x1 = int(box[0])\n",
        "    y1 = int(box[1])\n",
        "    x2 = int(box[2])\n",
        "    y2 = int(box[3])\n",
        "\n",
        "    dw = np.float32(1. / int(size[0]))\n",
        "    dh = np.float32(1. / int(size[1]))\n",
        "\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "    x = x1 + (w / 2)\n",
        "    y = y1 + (h / 2)\n",
        "\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return [x, y, w, h]\n",
        "def save_txt_file(img_jpg_file_name, size, img_box):\n",
        "    save_file_name = '/content/Dataset/labels/' +  img_jpg_file_name + '.txt'\n",
        "    #file_path = open(save_file_name, \"a+\")\n",
        "    with open(save_file_name ,'a+') as file_path:\n",
        "        for box in img_box:\n",
        "\n",
        "            cls_num = classes.index(box[0])\n",
        "\n",
        "            new_box = convert_annot(size, box[1:])\n",
        "\n",
        "            file_path.write(f\"{cls_num} {new_box[0]} {new_box[1]} {new_box[2]} {new_box[3]}\\n\")\n",
        "\n",
        "        file_path.flush()\n",
        "        file_path.close()\n",
        "def get_xml_data(file_path, img_xml_file):\n",
        "    img_path = file_path + '/' + img_xml_file + '.xml'\n",
        "    #print(img_path)\n",
        "\n",
        "    dom = parse(img_path)\n",
        "    root = dom.documentElement\n",
        "    img_name = root.getElementsByTagName(\"filename\")[0].childNodes[0].data\n",
        "    img_size = root.getElementsByTagName(\"size\")[0]\n",
        "    objects = root.getElementsByTagName(\"object\")\n",
        "    img_w = img_size.getElementsByTagName(\"width\")[0].childNodes[0].data\n",
        "    img_h = img_size.getElementsByTagName(\"height\")[0].childNodes[0].data\n",
        "    img_c = img_size.getElementsByTagName(\"depth\")[0].childNodes[0].data\n",
        "   \n",
        "    img_box = []\n",
        "    for box in objects:\n",
        "        cls_name = box.getElementsByTagName(\"name\")[0].childNodes[0].data\n",
        "        if cls_name=='helmet':\n",
        "            x1 = int(box.getElementsByTagName(\"xmin\")[0].childNodes[0].data)\n",
        "            y1 = int(box.getElementsByTagName(\"ymin\")[0].childNodes[0].data)\n",
        "            x2 = int(box.getElementsByTagName(\"xmax\")[0].childNodes[0].data)\n",
        "            y2 = int(box.getElementsByTagName(\"ymax\")[0].childNodes[0].data)\n",
        "\n",
        "            img_jpg_file_name = img_xml_file + '.jpg'\n",
        "            img_box.append([cls_name, x1, y1, x2, y2])\n",
        "\n",
        "    # test_dataset_box_feature(img_jpg_file_name, img_box)\n",
        "    save_txt_file(img_xml_file, [img_w, img_h], img_box)\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "from pathlib import Path\n",
        "from xml.dom.minidom import parse\n",
        "from shutil import copyfile\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIdVMr7oNYUR"
      },
      "source": [
        "!pip install -r requirements.txt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIrKk8zsNYRF"
      },
      "source": [
        "!pip install --no-deps '/kaggle/input/weightedboxesfusion/' > /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVYql1VAOxoO"
      },
      "source": [
        "%%writefile detect.py\n",
        "\"\"\"Run inference with a YOLOv5 model on images, videos, directories, streams\n",
        "\n",
        "Usage:\n",
        "    $ python path/to/detect.py --source path/to/img.jpg --weights yolov5s.pt --img 640\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "FILE = Path(__file__).absolute()\n",
        "sys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path\n",
        "from matplotlib import pyplot as plt\n",
        "from models.experimental import attempt_load\n",
        "from utils.datasets import LoadStreams, LoadImages\n",
        "from utils.general import check_img_size, check_requirements, check_imshow, colorstr, non_max_suppression, \\\n",
        "    apply_classifier, scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path, save_one_box\n",
        "from utils.plots import colors, plot_one_box\n",
        "from utils.torch_utils import select_device, load_classifier, time_sync\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def run(weights='yolov5s.pt',  # model.pt path(s)\n",
        "        source='data/images',  # file/dir/URL/glob, 0 for webcam\n",
        "        imgsz=640,  # inference size (pixels)\n",
        "        conf_thres=0.25,  # confidence threshold\n",
        "        iou_thres=0.45,  # NMS IOU threshold\n",
        "        max_det=1000,  # maximum detections per image\n",
        "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
        "        view_img=False,  # show results\n",
        "        save_txt=False,  # save results to *.txt\n",
        "        save_conf=False,  # save confidences in --save-txt labels\n",
        "        save_crop=False,  # save cropped prediction boxes\n",
        "        nosave=False,  # do not save images/videos\n",
        "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
        "        agnostic_nms=False,  # class-agnostic NMS\n",
        "        augment=False,  # augmented inference\n",
        "        visualize=False,  # visualize features\n",
        "        update=False,  # update all models\n",
        "        project='runs/detect',  # save results to project/name\n",
        "        name='exp',  # save results to project/name\n",
        "        exist_ok=False,  # existing project/name ok, do not increment\n",
        "        line_thickness=3,  # bounding box thickness (pixels)\n",
        "        hide_labels=False,  # hide labels\n",
        "        hide_conf=False,  # hide confidences\n",
        "        half=False,  # use FP16 half-precision inference\n",
        "        ):\n",
        "    imgsz=640\n",
        "    device = 'cpu'\n",
        "    \n",
        "    w = weights[0] if isinstance(weights, list) else weights\n",
        "    \n",
        "    stride, names = 64, [f'class{i}' for i in range(1000)]  # assign defaults\n",
        "    \n",
        "    model = attempt_load(weights, map_location=device).float()\n",
        "    \n",
        "    stride = int(model.stride.max())  # model stride\n",
        "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
        "    dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
        "    bs = 1  # batch_size\n",
        "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
        "    classes=None\n",
        "    agnostic_nms=False\n",
        "    times=[]\n",
        "    ids=[]\n",
        "    t0 = time.time()\n",
        "    sum=0\n",
        "    for en,(path, img, im0s, vid_cap) in enumerate(dataset):\n",
        "        all_total=[]\n",
        "        img = torch.from_numpy(img).to(device)\n",
        "        img = img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        if len(img.shape) == 3:\n",
        "            img = img[None]  # expand for batch dim\n",
        "        # Inference\n",
        "        t1 = time_sync()\n",
        "        pred1 = model(img, augment=augment)[0]\n",
        "        # NMS\n",
        "        pred = non_max_suppression(pred1, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
        "        t2 = time_sync()\n",
        "        times.append(t2-t1)\n",
        "        ids.append(path.split('/')[-1].split('.')[0])\n",
        "        \n",
        "        for i, det in enumerate(pred):  # detections per image\n",
        "            p, s, im0, frame = path, '', im0s.copy(), getattr(dataset, 'frame', 0)\n",
        "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
        "#             print('*'*20)\n",
        "#             if len(det)==0:\n",
        "#                 print(pred1)\n",
        "#             else:\n",
        "            if len(det)==0:\n",
        "                sum+=1\n",
        "            if len(det):\n",
        "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
        "                for *xyxy, conf, cls in reversed(det):\n",
        "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
        "                        line = (cls, *xywh)  # label format\n",
        "                        c = int(cls)  # integer class\n",
        "                        label = (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
        "                        w=im0.shape[1]\n",
        "                        x1=int(xyxy[0].cpu().numpy().item()) \n",
        "                        y1=int(xyxy[1].cpu().numpy().item())\n",
        "                        x2=int(xyxy[2].cpu().numpy().item())\n",
        "                        y2=int(xyxy[3].cpu().numpy().item())\n",
        "                        im0s=cv2.rectangle(im0s,(int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),5)\n",
        "                        cv2.imwrite(path,im0s)\n",
        "                        total=[x1,y1,x2,y2]\n",
        "                        if label!=None:\n",
        "                                all_total.append({\n",
        "                                'boxes': total,\n",
        "                                'scores': label})\n",
        "        np.save(path.split('/')[-1].split('.')[0]+'_1'+weights[0].split('/')[-1].split('.')[0]+'.npy',all_total)\n",
        "    print()\n",
        "    print('*'*20)\n",
        "    print('total time'+str(t2-t0))\n",
        "    print('*'*20)\n",
        "    np.save('/kaggle/working/times.npy',times)\n",
        "    np.save('/kaggle/working/ids.npy',ids)\n",
        "def parse_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', nargs='+', type=str, default='yolov5s.pt', help='model.pt path(s)')\n",
        "    parser.add_argument('--source', type=str, default='data/images', help='file/dir/URL/glob, 0 for webcam')\n",
        "    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')\n",
        "    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--view-img', action='store_true', help='show results')\n",
        "    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
        "    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
        "    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')\n",
        "    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
        "    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --class 0, or --class 0 2 3')\n",
        "    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--visualize', action='store_true', help='visualize features')\n",
        "    parser.add_argument('--update', action='store_true', help='update all models')\n",
        "    parser.add_argument('--project', default='runs/detect', help='save results to project/name')\n",
        "    parser.add_argument('--name', default='exp', help='save results to project/name')\n",
        "    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
        "    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')\n",
        "    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')\n",
        "    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')\n",
        "    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')\n",
        "    opt = parser.parse_args()\n",
        "    return opt\n",
        "\n",
        "\n",
        "def main(opt):\n",
        "    print(colorstr('detect: ') + ', '.join(f'{k}={v}' for k, v in vars(opt).items()))\n",
        "    check_requirements(exclude=('tensorboard', 'thop'))\n",
        "    run(**vars(opt))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    opt = parse_opt()\n",
        "    main(opt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJIzv49OxlD"
      },
      "source": [
        "!python detect.py --source /kaggle/working/Dataset/images/test  --weights /kaggle/input/weights-plate/last.pt --conf 0.25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NObjLXnOxh7"
      },
      "source": [
        "dk={}\n",
        "t=np.load('/kaggle/working/times.npy')\n",
        "i=np.load('/kaggle/working/ids.npy')\n",
        "for a,b in zip(t,i):\n",
        "    dk[b]=a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KiSs4dmOxfC"
      },
      "source": [
        "dk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdIy7sbUOxb5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0CCgTJFOxY7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmELdtUDOxV-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzUSY2R1OxTK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqpbkJCwOxP5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0WSIsKcOxM5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to9VWQsGOxJ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKvjNVNJOxGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cEaeLI1OxDn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjvBqKX2OxAw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}